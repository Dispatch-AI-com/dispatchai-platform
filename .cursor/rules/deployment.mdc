---
description: Deployment and infrastructure rules
alwaysApply: false
---

# Deployment & Infrastructure Rules

## Core Principles

Follow SOLID, DRY, KISS, and prioritize reliability and reproducibility.

## Docker Practices

### Dockerfile Best Practices

```dockerfile
# ✅ Good - Multi-stage build, minimal layers
# Stage 1: Dependencies
FROM node:20-alpine AS deps
WORKDIR /app
COPY package.json package-lock.json ./
RUN npm ci --only=production && npm cache clean --force

# Stage 2: Build
FROM node:20-alpine AS builder
WORKDIR /app
COPY . .
COPY --from=deps /app/node_modules ./node_modules
RUN npm run build

# Stage 3: Runtime
FROM node:20-alpine AS runner
WORKDIR /app
ENV NODE_ENV=production
COPY --from=builder /app/dist ./dist
COPY --from=builder /app/node_modules ./node_modules
COPY --from=builder /app/package.json ./
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nextjs -u 1001
USER nextjs
EXPOSE 3000
CMD ["npm", "start"]

# ❌ Bad - Single stage, no optimization
FROM node:20
WORKDIR /app
COPY . .
RUN npm install
RUN npm run build
EXPOSE 3000
CMD ["npm", "start"]
```

### Python Dockerfile

```dockerfile
# ✅ Good - Using uv for fast dependency management
FROM python:3.11-slim AS builder
COPY --from=ghcr.io/astral-sh/uv:latest /uv /usr/local/bin/uv
WORKDIR /app
COPY pyproject.toml uv.lock ./
RUN uv sync --frozen

FROM python:3.11-slim
WORKDIR /app
COPY --from=builder /app/.venv /app/.venv
COPY . .
ENV PATH="/app/.venv/bin:$PATH"
EXPOSE 8000
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]

# ❌ Bad - Slow pip install, no caching
FROM python:3.11
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
EXPOSE 8000
CMD ["python", "app.py"]
```

## Docker Compose

### Service Definitions

```yaml
# ✅ Good - Clear configuration, health checks
services:
  backend:
    build:
      context: ../apps/backend
      dockerfile: Dockerfile.uat
    container_name: dispatchai-api
    restart: unless-stopped
    ports:
      - "4000:4000"
    environment:
      - NODE_ENV=production
      - MONGODB_URI=${MONGODB_URI}
      - REDIS_HOST=redis
      - JWT_SECRET=${JWT_SECRET}
    depends_on:
      mongo:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - dispatchai-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  mongo:
    image: mongo:7
    container_name: dispatchai-mongodb
    restart: unless-stopped
    volumes:
      - mongo-data:/data/db
    healthcheck:
      test: ["CMD", "mongosh", "--quiet", "--eval", "db.runCommand({ ping: 1 }).ok"]
      interval: 10s
      timeout: 5s
      retries: 6

# ❌ Bad - No health checks, unclear dependencies
services:
  backend:
    build: .
    ports:
      - "4000:4000"
  mongo:
    image: mongo
```

### Network Configuration

```yaml
# ✅ Good - Isolated network with bridge driver
networks:
  dispatchai-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.25.0.0/16

# ❌ Bad - Using default bridge (potential conflicts)
```

## Environment Management

### Environment Files

```
# .env.shared (common across all environments)
MONGODB_URI=mongodb://mongo:27017/dispatchai
REDIS_HOST=redis
REDIS_PORT=6379

# .env.dev (development only)
DEBUG=true
LOG_LEVEL=debug

# .env.uat (UAT only)
DEBUG=false
LOG_LEVEL=info

# .env.prod (production only)
NODE_ENV=production
DEBUG=false
LOG_LEVEL=warn
```

**Best Practices:**
- Never commit `.env` files to version control
- Use `.env.example` as templates
- Prefix secrets with `SECRET_` or `PRIVATE_`
- Use different files per environment
- Document required variables in README

```bash
# ✅ Good - Proper .gitignore
.env
.env.local
.env.*.local
*.env

# ❌ Bad - Committing secrets
# .env files in git history
```

## CI/CD (GitHub Actions)

### Workflow Patterns

```yaml
# ✅ Good - Well-structured workflow
name: Deploy UAT

on:
  repository_dispatch:
    types: [deploy_uat]
  workflow_dispatch:

permissions:
  contents: read
  id-token: write

concurrency:
  group: deploy-uat
  cancel-in-progress: false

env:
  AWS_REGION: ap-southeast-2
  REMOTE_PROJECT_DIR: /opt/dispatchai-platform

jobs:
  deploy:
    name: Deploy to UAT EC2
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      
      - name: Setup SSH
        uses: webfactory/ssh-agent@v0.10.0
        with:
          ssh-private-key: ${{ secrets.UAT_SSH_KEY }}
      
      - name: Deploy via SSH
        env:
          UAT_SSH_HOST: ${{ secrets.UAT_SSH_HOST }}
          UAT_SSH_USER: ${{ secrets.UAT_SSH_USER }}
        run: |
          ssh ${UAT_SSH_USER}@${UAT_SSH_HOST} <<'EOF'
          set -euo pipefail
          cd "${REMOTE_PROJECT_DIR}"
          
          echo "==> Updating repo"
          git fetch --all --prune || true
          git pull --rebase || true
          
          echo "==> Logging into ECR"
          ACCOUNT_ID=$(aws sts get-caller-identity --query 'Account' --output text)
          aws ecr get-login-password --region ${AWS_REGION} \
            | docker login --username AWS --password-stdin \
            ${ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com
          
          echo "==> Pulling latest images"
          docker compose -f infra/docker-compose.uat.yml pull
          
          echo "==> Restarting containers"
          docker compose -f infra/docker-compose.uat.yml up -d
          
          echo "==> Cleaning up"
          docker image prune -f || true
          EOF

# ❌ Bad - No error handling, no cleanup
jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - run: ssh user@host "cd /app && git pull && docker compose up -d"
```

### Secrets Management

```yaml
# ✅ Good - Using GitHub Secrets
env:
  AWS_REGION: ${{ secrets.AWS_REGION }}
  SSH_KEY: ${{ secrets.UAT_SSH_KEY }}
  SSH_HOST: ${{ secrets.UAT_SSH_HOST }}

# ❌ Bad - Hardcoded values
env:
  AWS_REGION: us-east-1
  SSH_KEY: "ssh-rsa AAAAB3..."
```

**GitHub Secrets:**
- `UAT_SSH_KEY` - Private SSH key
- `UAT_SSH_HOST` - EC2 host IP
- `UAT_SSH_USER` - SSH username
- `AWS_REGION` - AWS region

## AWS ECR Deployment

### Image Tagging

```bash
# ✅ Good - Consistent tagging strategy
# Development builds
docker tag image:latest 123456789012.dkr.ecr.region.amazonaws.com/service:dev-$(date +%Y%m%d)

# UAT builds
docker tag image:latest 123456789012.dkr.ecr.region.amazonaws.com/service:uat-latest

# Production builds  
docker tag image:latest 123456789012.dkr.ecr.region.amazonaws.com/service:prod-$(git rev-parse --short HEAD)

# ❌ Bad - No tagging strategy
docker tag image latest
```

### ECR Login

```bash
# ✅ Good - Secure ECR authentication
aws ecr get-login-password --region ${AWS_REGION} \
  | docker login --username AWS --password-stdin \
  ${ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com

# ❌ Bad - Using deprecated login method
aws ecr get-login --region ${AWS_REGION} | sh
```

## Database Migrations

### MongoDB Migration Strategy

```typescript
// ✅ Good - Version-controlled migrations
// scripts/migrations/001-add-user-index.ts
export async function up(db: Db): Promise<void> {
  await db.collection('users').createIndex({ email: 1 }, { unique: true });
  await db.collection('users').createIndex({ 'greeting.message': 'text' });
}

export async function down(db: Db): Promise<void> {
  await db.collection('users').dropIndex({ email: 1 });
  await db.collection('users').dropIndex({ 'greeting.message': 'text' });
}

// Migration runner
const migrations = await readMigrations();
for (const migration of migrations) {
  if (needsMigration(migration)) {
    await migration.up(db);
    await recordMigration(migration.version);
  }
}

# ❌ Bad - Manual migrations, no versioning
# Manually running mongo commands in production
```

## Monitoring & Logging

### Log Aggregation

```yaml
# ✅ Good - Centralized logging
services:
  backend:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=backend,env=uat"

  fluentd:
    image: fluentd:v1.16-1
    volumes:
      - ./fluentd:/fluentd/etc
    ports:
      - "24224:24224"

# ❌ Bad - No log management
# Logs filling up disk, no aggregation
```

### Health Checks

```typescript
// ✅ Good - Comprehensive health checks
@Get('/health')
async healthCheck() {
  return {
    status: 'ok',
    timestamp: new Date().toISOString(),
    services: {
      database: await this.checkDatabase(),
      redis: await this.checkRedis(),
      ai_service: await this.checkAiService(),
    },
  };
}

private async checkDatabase(): Promise<'ok' | 'down'> {
  try {
    await this.mongoClient.db('admin').command({ ping: 1 });
    return 'ok';
  } catch {
    return 'down';
  }
}

// ❌ Bad - No health checks
@Get('/health')
async healthCheck() {
  return { status: 'ok' };
}
```

## Rollback Strategies

### Blue-Green Deployment

```bash
# ✅ Good - Zero-downtime deployment
# 1. Deploy new version alongside old
docker compose -f docker-compose.new.yml up -d

# 2. Run smoke tests
./scripts/smoke-tests.sh

# 3. Switch traffic
./scripts/switch-traffic.sh new

# 4. Monitor for 5 minutes
sleep 300

# 5. Clean up old version
docker compose -f docker-compose.old.yml down

# ❌ Bad - In-place updates
docker compose down && docker compose up -d
# Downtime during restart
```

## Security Practices

### Least Privilege

```yaml
# ✅ Good - Non-root user in containers
FROM node:20-alpine
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nextjs -u 1001
USER nextjs

# ❌ Bad - Running as root
FROM node:20
# No USER directive, runs as root
```

### Secrets in Containers

```bash
# ✅ Good - Using Docker secrets or env files
docker compose config
docker compose up -d

# Or with secrets
echo "my-secret" | docker secret create jwt_secret -
docker service create --secret jwt_secret myapp

# ❌ Bad - Passing secrets via CLI
docker run -e JWT_SECRET=hardcoded-secret myapp
```

## Common Pitfalls to Avoid

1. **Don't commit secrets** - Use environment variables
2. **Don't skip health checks** - Always implement them
3. **Don't ignore logs** - Set up log aggregation
4. **Don't deploy without tests** - Run tests in CI/CD
5. **Don't use latest tags** - Use specific versions
6. **Don't skip backups** - Regular database backups
7. **Don't ignore resource limits** - Set memory/CPU limits
8. **Don't hardcode values** - Use configuration
9. **Don't skip rollback plan** - Always have a revert strategy
10. **Don't forget monitoring** - Set up alerts and dashboards